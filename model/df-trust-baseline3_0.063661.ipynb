{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import time\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy import sparse\n",
    "from scipy.sparse import csr_matrix\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
    "\n",
    "#特征重要性\n",
    "def display_importances(feature_importance_df_):\n",
    "    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:40].index\n",
    "    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n",
    "    plt.figure(figsize=(8, 10))\n",
    "    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "    plt.title('LightGBM Features (avg over folds)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    " \n",
    "#聚合求count\n",
    "def feature_count(data, features=[]):\n",
    "    if len(set(features)) != len(features):\n",
    "        print('equal feature !!!!')\n",
    "        return data\n",
    "    new_feature = 'count'\n",
    "    for i in features:\n",
    "        new_feature += '_' + i.replace('add_', '')\n",
    "    try:\n",
    "        del data[new_feature]\n",
    "    except:\n",
    "        pass\n",
    "    temp = data.groupby(features).size().reset_index().rename(columns={0: new_feature})\n",
    "    data = data.merge(temp, 'left', on=features)\n",
    "    new_num_features.append(new_feature)\n",
    "    return data    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/train_dataset.csv')\n",
    "test = pd.read_csv('../input/test_dataset.csv')\n",
    "\n",
    "#删除id\n",
    "test_id = test['用户编码'].copy()\n",
    "\n",
    "train.drop(\"用户编码\", axis = 1, inplace = True)\n",
    "test.drop(\"用户编码\", axis = 1, inplace = True)\n",
    "\n",
    "label = train['信用分'].copy()\n",
    "train.drop(['信用分'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "#特征工程\n",
    "data = pd.concat([train, test])\n",
    "\n",
    "#原始的类别和数值特征\n",
    "ori_cat_features = ['用户实名制是否通过核实','是否大学生客户','是否黑名单客户','是否4G不健康客户','缴费用户当前是否欠费缴费','是否经常逛商场的人','当月是否逛过福州仓山万达',\n",
    "                    '当月是否到过福州山姆会员店','当月是否看电影','当月是否景点游览','当月是否体育场馆消费']\n",
    "ori_num_features = ['用户年龄','用户网龄（月）','用户最近一次缴费距今时长（月）','缴费用户最近一次缴费金额（元）','用户近6个月平均消费值（元）','用户账单当月总费用（元）',\n",
    "                    '用户当月账户余额（元）','用户话费敏感度','当月通话交往圈人数','近三个月月均商场出现次数','当月网购类应用使用次数','当月物流快递类应用使用次数',\n",
    "                    '当月金融理财类应用使用总次数','当月视频播放类应用使用次数','当月飞机类应用使用次数','当月火车类应用使用次数','当月旅游资讯类应用使用次数']\n",
    "ori_col = data.columns.tolist()\n",
    "                    \n",
    "#对年龄异常值取众数填充\n",
    "data.loc[data['用户年龄']==0, '用户年龄'] = data['用户年龄'].mode()\n",
    "\n",
    "#年龄特征\n",
    "data['网龄/年龄'] = data['用户网龄（月）'] / data['用户年龄']\n",
    "data['网龄年龄差'] = data['用户年龄'] - data['用户网龄（月）']/12\n",
    "\n",
    "#对金额相关特征做组合\n",
    "data['缴费金额是否能覆盖当月账单'] = data['缴费用户最近一次缴费金额（元）'] - data['用户账单当月总费用（元）']\n",
    "data['最近一次交费是否超过平均消费额'] = data['缴费用户最近一次缴费金额（元）'] - data['用户近6个月平均消费值（元）']\n",
    "data['当月账单是否超过平均消费额'] = data['用户账单当月总费用（元）'] - data['用户近6个月平均消费值（元）']\n",
    "data['缴费习惯'] = data['缴费用户最近一次缴费金额（元）'] / (data['用户近6个月平均消费值（元）'] + 0.001)\n",
    "data['通话人均花费'] = data['用户账单当月总费用（元）'] / (data['当月通话交往圈人数']+1)\n",
    "data['近半年账单'] = data['用户近6个月平均消费值（元）']*6 + data['用户账单当月总费用（元）']\n",
    "data['最近账单稳定性'] = data['用户账单当月总费用（元）'] / (data['用户近6个月平均消费值（元）'] + 0.001)\n",
    "data['费用/余额'] = data['用户账单当月总费用（元）'] / (data['缴费用户最近一次缴费金额（元）'] + 0.001)\n",
    "data['账户余额利用率'] = data['用户账单当月总费用（元）'] / (data['用户当月账户余额（元）'] + 0.001)\n",
    "\n",
    "#对次数特征做组合\n",
    "data['交通类应用使用次数'] = data['当月飞机类应用使用次数'] + data['当月火车类应用使用次数']\n",
    "\n",
    "new_num_features = [i for i in data.columns.tolist() if i not in ori_col]\n",
    "\n",
    "#充值金额是整数，和小数，应该对应不同的充值途径\n",
    "def top_up_amount_method(s):\n",
    "    \n",
    "    if(s == 0):\n",
    "        return 0\n",
    "    elif(s % 10 == 0):\n",
    "        return 1\n",
    "    elif((s / 0.998) % 10 ==0):\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "data['充值方式1'] = data['缴费用户最近一次缴费金额（元）'].apply(top_up_amount_method)\n",
    "\n",
    "def real_top_up_amount(s):\n",
    "    if((s / 0.998) % 10 ==0):\n",
    "        return s/0.998\n",
    "    else:\n",
    "        return s\n",
    "data[\"充值方式2\"] = data['缴费用户最近一次缴费金额（元）'].apply(real_top_up_amount)\n",
    "\n",
    "#对类别特征进行组合，是否可以得出更好的结果\n",
    "data['是否去过高档商场'] = data['当月是否逛过福州仓山万达'] + data['当月是否到过福州山姆会员店']\n",
    "data['是否去过高档商场'] = data['是否去过高档商场'].map(lambda x:1 if x>=1 else 0)\n",
    "data['是否_商场_电影'] = data['是否去过高档商场'] * data['当月是否看电影']\n",
    "data['是否_商场_旅游'] = data['是否去过高档商场'] * data['当月是否景点游览']\n",
    "data['是否_商场_体育馆'] = data['是否去过高档商场'] * data['当月是否体育场馆消费']\n",
    "data['是否_电影_体育馆'] = data['当月是否看电影'] * data['当月是否体育场馆消费']\n",
    "data['是否_电影_旅游'] = data['当月是否看电影'] * data['当月是否景点游览']\n",
    "data['是否_旅游_体育馆'] = data['当月是否景点游览'] * data['当月是否体育场馆消费']\n",
    "data['是否_商场_旅游_体育馆'] = data['是否去过高档商场'] * data['当月是否景点游览'] * data['当月是否体育场馆消费']\n",
    "data['是否_商场_电影_体育馆'] = data['是否去过高档商场'] * data['当月是否看电影'] * data['当月是否体育场馆消费']\n",
    "data['是否_商场_电影_旅游'] = data['是否去过高档商场'] * data['当月是否看电影'] * data['当月是否景点游览']\n",
    "data['是否_体育馆_电影_旅游'] = data['当月是否体育场馆消费'] * data['当月是否看电影'] * data['当月是否景点游览']\n",
    "data['是否_商场_体育馆_电影_旅游'] = data['是否去过高档商场'] * data['当月是否体育场馆消费'] * data['当月是否看电影'] * data['当月是否景点游览']\n",
    "\n",
    "new_cat_features = [i for i in data.columns.tolist() if i not in ori_col and i not in new_num_features]\n",
    "\n",
    "#对一些特征分段\n",
    "discretize_features=['交通类应用使用次数','当月物流快递类应用使用次数','当月飞机类应用使用次数','当月火车类应用使用次数','当月旅游资讯类应用使用次数']\n",
    "def map_discretize(x):\n",
    "        if x==0:\n",
    "            return 0\n",
    "        elif x<=5:\n",
    "            return 1\n",
    "        elif x<=15:\n",
    "            return 2\n",
    "        elif x<=50:\n",
    "            return 3\n",
    "        elif x<=100:\n",
    "            return 4\n",
    "        else:\n",
    "            return 5\n",
    "        \n",
    "for col in discretize_features:\n",
    "    data[col]=data[col].map(lambda x:map_discretize(x))\n",
    "\n",
    "#离散化\n",
    "transform_value_feature=['用户年龄','用户网龄（月）','当月通话交往圈人数','近三个月月均商场出现次数','当月网购类应用使用次数','当月物流快递类应用使用次数'\n",
    "                            ,'当月金融理财类应用使用总次数','当月视频播放类应用使用次数','当月飞机类应用使用次数','当月火车类应用使用次数','当月旅游资讯类应用使用次数']\n",
    "user_fea=['缴费用户最近一次缴费金额（元）','用户近6个月平均消费值（元）','用户账单当月总费用（元）','用户当月账户余额（元）']\n",
    "log_features=['当月网购类应用使用次数','当月金融理财类应用使用总次数','当月物流快递类应用使用次数','当月视频播放类应用使用次数']\n",
    "\n",
    "for col in transform_value_feature+log_features:\n",
    "    #取出最高99.9%值\n",
    "    ulimit=np.percentile(data[col].values,99.9)\n",
    "    #取出最低0.1%值\n",
    "    llimit=np.percentile(data[col].values,0.1)\n",
    "    data.loc[data[col]>ulimit,col]=ulimit\n",
    "    data.loc[data[col]<llimit,col]=llimit\n",
    "    \n",
    "for col in user_fea+transform_value_feature+log_features:\n",
    "    data[col]=data[col].map(lambda x:np.log1p(x))\n",
    "    \n",
    "#聚合特征\n",
    "# data = feature_count(data, ['用户年龄'])\n",
    "# data = feature_count(data, ['用户网龄（月）'])\n",
    "# data = feature_count(data, ['用户最近一次缴费距今时长（月）'])\n",
    "# data = feature_count(data, ['缴费用户最近一次缴费金额（元）'])\n",
    "# data = feature_count(data, ['用户近6个月平均消费值（元）'])\n",
    "# data = feature_count(data, ['用户账单当月总费用（元）'])\n",
    "# data = feature_count(data, ['用户话费敏感度'])\n",
    "# data = feature_count(data, ['当月通话交往圈人数'])\n",
    "# data = feature_count(data, ['近三个月月均商场出现次数'])\n",
    "# data = feature_count(data, ['最近一次交费是否超过平均消费额'])\n",
    "# data = feature_count(data, ['当月账单是否超过平均消费额'])\n",
    "\n",
    "# data = feature_count(data, ['用户话费敏感度','用户年龄'])\n",
    "# data = feature_count(data, ['用户话费敏感度','用户网龄（月）'])\n",
    "# data = feature_count(data, ['用户话费敏感度','用户最近一次缴费距今时长（月）'])\n",
    "# data = feature_count(data, ['用户话费敏感度','缴费用户最近一次缴费金额（元）'])\n",
    "# data = feature_count(data, ['用户话费敏感度','用户近6个月平均消费值（元）'])\n",
    "# data = feature_count(data, ['用户话费敏感度','用户账单当月总费用（元）'])\n",
    "# data = feature_count(data, ['用户话费敏感度','当月通话交往圈人数'])\n",
    "# data = feature_count(data, ['用户话费敏感度','近三个月月均商场出现次数'])\n",
    "# data = feature_count(data, ['用户话费敏感度','最近一次交费是否超过平均消费额'])\n",
    "# data = feature_count(data, ['用户话费敏感度','当月账单是否超过平均消费额'])\n",
    "\n",
    "# #聚合其他列的特征\n",
    "# sparse_feature = ['用户年龄','用户网龄（月）','用户最近一次缴费距今时长（月）','用户话费敏感度']\n",
    "# dense_feature = ['缴费用户最近一次缴费金额（元）','用户近6个月平均消费值（元）','用户账单当月总费用（元）',\n",
    "#                     '用户当月账户余额（元）']\n",
    "\n",
    "# def get_new_columns(name,aggs):\n",
    "#     l=[]\n",
    "#     for k in aggs.keys():\n",
    "#         for agg in aggs[k]:\n",
    "#             if str(type(agg))==\"<class 'function'>\":\n",
    "#                 l.append(name + '_' + k + '_' + 'other')\n",
    "#             else:\n",
    "#                 l.append(name + '_' + k + '_' + agg)\n",
    "#     return l\n",
    "# for d in tqdm(sparse_feature):\n",
    "#     aggs={}\n",
    "#     for s in sparse_feature:\n",
    "#         aggs[s]=['count','nunique']\n",
    "#     for den in dense_feature:\n",
    "#         aggs[den]=['mean','max','min','std']\n",
    "#     aggs.pop(d)\n",
    "#     temp=data.groupby(d).agg(aggs).reset_index()\n",
    "#     temp.columns=[d]+get_new_columns(d,aggs)\n",
    "#     new_num_features.append(get_new_columns(d,aggs))\n",
    "#     data=pd.merge(data,temp,on=d,how='left')\n",
    "\n",
    "#记录特征\n",
    "cat_features = new_cat_features + ori_cat_features\n",
    "num_features = new_num_features + ori_num_features\n",
    "\n",
    "for i in cat_features:\n",
    "    data[i] = data[i].astype('category')\n",
    "for i in num_features:\n",
    "    data[i] = data[i].astype('float')\n",
    "\n",
    "# #类别特征做one-hot    \n",
    "# for feature in cat_features:\n",
    "#     try:\n",
    "#         data[feature] = LabelEncoder().fit_transform(data[feature].apply(int))\n",
    "#     except:\n",
    "#         data[feature] = LabelEncoder().fit_transform(data[feature])    \n",
    " \n",
    "\n",
    "train = data[:train.shape[0]]\n",
    "test = data[train.shape[0]:]    \n",
    "\n",
    "\n",
    "# train_x=train[num_features]\n",
    "# test_x=test[num_features]\n",
    "# enc = OneHotEncoder()\n",
    "# for feature in cat_features:\n",
    "#     enc.fit(data[feature].values.reshape(-1, 1))\n",
    "#     train_a= enc.transform(train[feature].values.reshape(-1, 1))\n",
    "#     test_a = enc.transform(test[feature].values.reshape(-1, 1))\n",
    "#     train= sparse.hstack((train_x, train_a), 'csr')\n",
    "#     test = sparse.hstack((test_x, test_a), 'csr')\n",
    "    \n",
    "    \n",
    "# #CountVectorizer()特征,在本题中没有合适的量\n",
    "# vector_feature = []\n",
    "# # for i in vector_feature:\n",
    "# #     data[i] = data[i].astype('str')\n",
    "# #     train[i] = train[i].astype('str')\n",
    "# #     test[i] = test[i].astype('str')\n",
    "\n",
    "    \n",
    "\n",
    "# cv=CountVectorizer()\n",
    "# for feature in vector_feature:\n",
    "#     cv.fit(data[feature])\n",
    "#     train_a = cv.transform(train[feature])\n",
    "#     test_a = cv.transform(test[feature])\n",
    "#     train = sparse.hstack((train_x, train_a), 'csr')\n",
    "#     test = sparse.hstack((test_x, test_a), 'csr')\n",
    "\n",
    "\n",
    "#开始训练\n",
    "# kf = StratifiedKFold(n_splits=5, random_state=2019, shuffle=False)\n",
    "# training_time = 0 \n",
    "# feature_importance_df = pd.DataFrame()\n",
    "# best_score = []\n",
    "# sub_list = []\n",
    "\n",
    "# clf = lgb.LGBMRegressor(\n",
    "#           boosting_type='gbdt', num_leaves=31, reg_alpha=2.2, reg_lambda=1.5,\n",
    "#           max_depth=-1, n_estimators=2000,\n",
    "#           subsample=0.8, colsample_bytree=0.7, subsample_freq=1,\n",
    "#           learning_rate=0.03, random_state=2019, n_jobs=-1)\n",
    "\n",
    "# for i, (train_index, val_index) in enumerate(kf.split(train, label)):\n",
    "#      t0 = time.time()\n",
    "#      X_train, y_train = train.loc[train_index,:], label[train_index]\n",
    "#      X_val, y_val     = train.loc[val_index,:],   label[val_index]\n",
    "#      #X_train, y_train = train[train_index], label[train_index]\n",
    "#      #X_val,    y_val   = train[val_index],   label[val_index]\n",
    "#      #clf.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_val, y_val)],\\\n",
    "#       #        eval_metric='mae', early_stopping_rounds=200, verbose=200, categorical_feature=cat_features)\n",
    "#      clf.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_val, y_val)],\\\n",
    "#               eval_metric='mae', early_stopping_rounds=200, verbose=200)\n",
    "#      pred_val = clf.predict(X_val, num_iteration=clf.best_iteration_)\n",
    "#      vali_mae = mean_absolute_error(y_val, np.round(pred_val))\n",
    "#      best_score.append(1/(1+vali_mae))\n",
    "#      pred_test = clf.predict(test,num_iteration=clf.best_iteration_)\n",
    "     \n",
    "#      fold_importance_df = pd.DataFrame()\n",
    "#      fold_importance_df[\"feature\"] = list(X_train.columns)\n",
    "#      fold_importance_df[\"importance\"] = clf.feature_importances_\n",
    "#      fold_importance_df[\"fold\"] = i + 1\n",
    "#      feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "     \n",
    "#      sub_list.append(pred_test)\n",
    "#      t = (time.time() - t0) / 60\n",
    "#      training_time += t\n",
    "     \n",
    "#      print(\"This round cost time:{:.2f} minutes, lgb scor:{:.8f},\\n\".format(t, 1/(1+vali_mae)))\n",
    "        \n",
    "# pred_test = np.mean(np.array(sub_list), axis=0)\n",
    "# print(best_score, '\\n', np.mean(best_score), np.std(best_score))\n",
    "# print(\"Total training time cost:{:.2f} minutes\".format(training_time))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "94c861e1ea941e693424577b29149908c3eb9a3e"
   },
   "outputs": [],
   "source": [
    "for i in cat_features:\n",
    "    train[i] = train[i].astype('int')\n",
    "    test[i]  = test[i].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "dd57ea9108a9eb7d778d4a37ac5fcffb40430d80"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold,GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "38d33e8136da5fbf512b305f39a91cf83ab9a688"
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(train,label,test_size=0.25,random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "521473c92aabaa83a75b37639255ef9bc3d116b5"
   },
   "outputs": [],
   "source": [
    "clf1 = lgb.LGBMRegressor(boosting_type='gbdt',num_leaves=31,max_depth=-1,\n",
    "                n_estimators=2000,subsample=0.8,\n",
    "                subsample_freq=1,colsample_bytree=0.7,\n",
    "                random_state=2019,n_jobs=-1)\n",
    "\n",
    "clf2 = lgb.LGBMRegressor(boosting_type='gbdt',num_leaves=31,max_depth=-1,\n",
    "                n_estimators=2000,subsample=0.8,\n",
    "                subsample_freq=1,colsample_bytree=0.7,\n",
    "                random_state=2018,n_jobs=-1)\n",
    "\n",
    "clf3 = XGBRegressor(n_estimators=2000,silent=True,\n",
    "            objective='reg:linear',booster='gbtree',n_jobs=-1,gamma=0,\n",
    "            subsample=0.8,colsample_bytree=0.7,colsample_bylevel=1,\n",
    "            scale_pos_weight=1,base_score=0.5,random_state=2017)\n",
    "\n",
    "clf4 = XGBRegressor(max_depth=4,learning_rate=0.03,n_estimators=2000,silent=True,\n",
    "            objective='reg:linear',booster='gbtree',n_jobs=-1,gamma=0,\n",
    "            subsample=0.8,colsample_bytree=0.7,colsample_bylevel=1,\n",
    "            scale_pos_weight=1,base_score=0.5,random_state=2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "7c0155a7c3eaea10f1ad2d010bb03eff92c65af1"
   },
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=10,random_state=2015,shuffle=False)\n",
    "best_score = []\n",
    "sub_list = []\n",
    "\n",
    "param_test ={\n",
    "   'reg_alpha' :[0.015,0.03,0.05],\n",
    "   'reg_lambda':[0.8,1.0,1.2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "c0d2f12202802d414705b124ef704f6a916b4a2e"
   },
   "outputs": [],
   "source": [
    "# grid search 寻找最优超参数\n",
    "grid_search = GridSearchCV(estimator=clf3,param_grid=param_test,verbose=1,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "5fd3775a6e1c3fb27b2ee8cc8478b5e6cb3089f8",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed: 31.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.7, gamma=0, importance_type='gain',\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=2000, n_jobs=-1,\n",
       "       nthread=None, objective='reg:linear', random_state=2017,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=0.8),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'reg_alpha': [0.015, 0.03, 0.05], 'reg_lambda': [0.8, 1.0, 1.2]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train,y_train,eval_metric='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "4d8c06b62b68e65025b6b5c47b002a71ab7afd59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7909546015882323\n",
      "{'reg_alpha': 0.03, 'reg_lambda': 1.0}\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.score(X_test,y_test))\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "ad107390185fea4b7698a7a62665c22f78bf3c5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 110 rounds.\n",
      "[200]\ttraining's l1: 13.2923\ttraining's l2: 291.574\tvalid_1's l1: 15.2065\tvalid_1's l2: 392.576\n",
      "[400]\ttraining's l1: 12.216\ttraining's l2: 245.473\tvalid_1's l1: 15.1972\tvalid_1's l2: 392.254\n",
      "Early stopping, best iteration is:\n",
      "[298]\ttraining's l1: 12.7325\ttraining's l2: 267.036\tvalid_1's l1: 15.1719\tvalid_1's l2: 390.895\n",
      "Training until validation scores don't improve for 110 rounds.\n",
      "[200]\ttraining's l2: 292.096\ttraining's rmse: 17.0908\tvalid_1's l2: 393.72\tvalid_1's rmse: 19.8424\n",
      "[400]\ttraining's l2: 246.412\ttraining's rmse: 15.6975\tvalid_1's l2: 394.809\tvalid_1's rmse: 19.8698\n",
      "Early stopping, best iteration is:\n",
      "[292]\ttraining's l2: 268.8\ttraining's rmse: 16.3951\tvalid_1's l2: 393.149\tvalid_1's rmse: 19.828\n",
      "[0]\tvalidation_0-mae:555.956\tvalidation_1-mae:554.664\n",
      "Multiple eval metrics have been passed: 'validation_1-mae' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mae hasn't improved in 100 rounds.\n",
      "[200]\tvalidation_0-mae:14.535\tvalidation_1-mae:15.3088\n",
      "[400]\tvalidation_0-mae:14.1958\tvalidation_1-mae:15.1984\n",
      "[600]\tvalidation_0-mae:13.943\tvalidation_1-mae:15.1348\n",
      "Stopping. Best iteration:\n",
      "[649]\tvalidation_0-mae:13.8825\tvalidation_1-mae:15.125\n",
      "\n",
      "[0]\tvalidation_0-rmse:600.598\tvalidation_1-rmse:599.41\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[200]\tvalidation_0-rmse:19.1108\tvalidation_1-rmse:20.2796\n",
      "[400]\tvalidation_0-rmse:18.5292\tvalidation_1-rmse:19.9201\n",
      "[600]\tvalidation_0-rmse:18.2315\tvalidation_1-rmse:19.858\n",
      "[800]\tvalidation_0-rmse:17.9766\tvalidation_1-rmse:19.8218\n",
      "[1000]\tvalidation_0-rmse:17.7473\tvalidation_1-rmse:19.8049\n",
      "[1200]\tvalidation_0-rmse:17.5387\tvalidation_1-rmse:19.7942\n",
      "[1400]\tvalidation_0-rmse:17.3356\tvalidation_1-rmse:19.7877\n",
      "[1600]\tvalidation_0-rmse:17.1496\tvalidation_1-rmse:19.7747\n",
      "[1800]\tvalidation_0-rmse:16.9702\tvalidation_1-rmse:19.7716\n",
      "Stopping. Best iteration:\n",
      "[1701]\tvalidation_0-rmse:17.0573\tvalidation_1-rmse:19.7708\n",
      "\n",
      "Round:1.0,clf1 score:0.0618318,clf2 score:0.0617798,clf3 score:0.0620470,clf4 score:0.0621010,fusion score:0.0623150\n",
      "\n",
      "Training until validation scores don't improve for 110 rounds.\n",
      "[200]\ttraining's l1: 13.3099\ttraining's l2: 292.993\tvalid_1's l1: 15.0533\tvalid_1's l2: 380.324\n",
      "Early stopping, best iteration is:\n",
      "[180]\ttraining's l1: 13.429\ttraining's l2: 298.468\tvalid_1's l1: 15.0507\tvalid_1's l2: 380.236\n",
      "Training until validation scores don't improve for 110 rounds.\n",
      "[200]\ttraining's l2: 292.95\ttraining's rmse: 17.1158\tvalid_1's l2: 382.455\tvalid_1's rmse: 19.5565\n",
      "Early stopping, best iteration is:\n",
      "[203]\ttraining's l2: 292.098\ttraining's rmse: 17.0909\tvalid_1's l2: 382.354\tvalid_1's rmse: 19.5539\n",
      "[0]\tvalidation_0-mae:555.873\tvalidation_1-mae:555.08\n",
      "Multiple eval metrics have been passed: 'validation_1-mae' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mae hasn't improved in 100 rounds.\n",
      "[200]\tvalidation_0-mae:14.5324\tvalidation_1-mae:15.2721\n",
      "[400]\tvalidation_0-mae:14.2099\tvalidation_1-mae:15.1711\n",
      "[600]\tvalidation_0-mae:13.9575\tvalidation_1-mae:15.1618\n",
      "Stopping. Best iteration:\n",
      "[531]\tvalidation_0-mae:14.0404\tvalidation_1-mae:15.1583\n",
      "\n",
      "[0]\tvalidation_0-rmse:600.554\tvalidation_1-rmse:599.787\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[200]\tvalidation_0-rmse:19.1308\tvalidation_1-rmse:20.0969\n",
      "[400]\tvalidation_0-rmse:18.5654\tvalidation_1-rmse:19.6992\n",
      "[600]\tvalidation_0-rmse:18.259\tvalidation_1-rmse:19.5949\n",
      "[800]\tvalidation_0-rmse:18.0103\tvalidation_1-rmse:19.5466\n",
      "[1000]\tvalidation_0-rmse:17.7861\tvalidation_1-rmse:19.5149\n",
      "[1200]\tvalidation_0-rmse:17.5769\tvalidation_1-rmse:19.4892\n",
      "[1400]\tvalidation_0-rmse:17.3774\tvalidation_1-rmse:19.4734\n",
      "[1600]\tvalidation_0-rmse:17.1861\tvalidation_1-rmse:19.4627\n",
      "[1800]\tvalidation_0-rmse:17.0071\tvalidation_1-rmse:19.4577\n",
      "[1999]\tvalidation_0-rmse:16.8339\tvalidation_1-rmse:19.4493\n",
      "Round:2.0,clf1 score:0.0623150,clf2 score:0.0620351,clf3 score:0.0618785,clf4 score:0.0624288,fusion score:0.0625407\n",
      "\n",
      "Training until validation scores don't improve for 110 rounds.\n",
      "[200]\ttraining's l1: 13.3327\ttraining's l2: 293.599\tvalid_1's l1: 14.6737\tvalid_1's l2: 372.244\n",
      "Early stopping, best iteration is:\n",
      "[223]\ttraining's l1: 13.2044\ttraining's l2: 287.639\tvalid_1's l1: 14.6639\tvalid_1's l2: 371.648\n",
      "Training until validation scores don't improve for 110 rounds.\n",
      "[200]\ttraining's l2: 294.718\ttraining's rmse: 17.1673\tvalid_1's l2: 371.561\tvalid_1's rmse: 19.2759\n",
      "Early stopping, best iteration is:\n",
      "[185]\ttraining's l2: 298.987\ttraining's rmse: 17.2912\tvalid_1's l2: 371.341\tvalid_1's rmse: 19.2702\n",
      "[0]\tvalidation_0-mae:555.839\tvalidation_1-mae:555.377\n",
      "Multiple eval metrics have been passed: 'validation_1-mae' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mae hasn't improved in 100 rounds.\n",
      "[200]\tvalidation_0-mae:14.601\tvalidation_1-mae:14.8294\n",
      "[400]\tvalidation_0-mae:14.2525\tvalidation_1-mae:14.7143\n",
      "[600]\tvalidation_0-mae:13.9883\tvalidation_1-mae:14.6777\n",
      "Stopping. Best iteration:\n",
      "[655]\tvalidation_0-mae:13.9229\tvalidation_1-mae:14.6642\n",
      "\n",
      "[0]\tvalidation_0-rmse:600.519\tvalidation_1-rmse:600.105\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[200]\tvalidation_0-rmse:19.1737\tvalidation_1-rmse:19.6539\n",
      "[400]\tvalidation_0-rmse:18.6121\tvalidation_1-rmse:19.3628\n",
      "[600]\tvalidation_0-rmse:18.3196\tvalidation_1-rmse:19.2956\n",
      "[800]\tvalidation_0-rmse:18.0606\tvalidation_1-rmse:19.2522\n",
      "[1000]\tvalidation_0-rmse:17.8303\tvalidation_1-rmse:19.2368\n",
      "Stopping. Best iteration:\n",
      "[1078]\tvalidation_0-rmse:17.7501\tvalidation_1-rmse:19.2313\n",
      "\n",
      "Round:3.0,clf1 score:0.0638462,clf2 score:0.0638808,clf3 score:0.0638510,clf4 score:0.0640531,fusion score:0.0643496\n",
      "\n",
      "Training until validation scores don't improve for 110 rounds.\n",
      "[200]\ttraining's l1: 13.3184\ttraining's l2: 293.165\tvalid_1's l1: 14.9867\tvalid_1's l2: 378.037\n",
      "Early stopping, best iteration is:\n",
      "[219]\ttraining's l1: 13.209\ttraining's l2: 287.925\tvalid_1's l1: 14.9798\tvalid_1's l2: 377.538\n",
      "Training until validation scores don't improve for 110 rounds.\n",
      "[200]\ttraining's l2: 293.11\ttraining's rmse: 17.1205\tvalid_1's l2: 378.281\tvalid_1's rmse: 19.4494\n",
      "Early stopping, best iteration is:\n",
      "[208]\ttraining's l2: 290.961\ttraining's rmse: 17.0576\tvalid_1's l2: 377.978\tvalid_1's rmse: 19.4416\n",
      "[0]\tvalidation_0-mae:555.837\tvalidation_1-mae:555.722\n",
      "Multiple eval metrics have been passed: 'validation_1-mae' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mae hasn't improved in 100 rounds.\n",
      "[200]\tvalidation_0-mae:14.5326\tvalidation_1-mae:15.137\n",
      "[400]\tvalidation_0-mae:14.2092\tvalidation_1-mae:15.0335\n",
      "[600]\tvalidation_0-mae:13.9617\tvalidation_1-mae:14.9986\n",
      "[800]\tvalidation_0-mae:13.7384\tvalidation_1-mae:14.9926\n",
      "Stopping. Best iteration:\n",
      "[748]\tvalidation_0-mae:13.7924\tvalidation_1-mae:14.9869\n",
      "\n",
      "[0]\tvalidation_0-rmse:600.486\tvalidation_1-rmse:600.387\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[200]\tvalidation_0-rmse:19.1323\tvalidation_1-rmse:19.8515\n",
      "[400]\tvalidation_0-rmse:18.5624\tvalidation_1-rmse:19.5304\n",
      "[600]\tvalidation_0-rmse:18.2564\tvalidation_1-rmse:19.4404\n",
      "[800]\tvalidation_0-rmse:18.0047\tvalidation_1-rmse:19.4004\n",
      "[1000]\tvalidation_0-rmse:17.7826\tvalidation_1-rmse:19.3934\n",
      "[1200]\tvalidation_0-rmse:17.5727\tvalidation_1-rmse:19.3776\n",
      "[1400]\tvalidation_0-rmse:17.3693\tvalidation_1-rmse:19.3719\n",
      "Stopping. Best iteration:\n",
      "[1492]\tvalidation_0-rmse:17.2835\tvalidation_1-rmse:19.3657\n",
      "\n",
      "Round:4.0,clf1 score:0.0625660,clf2 score:0.0624628,clf3 score:0.0625551,clf4 score:0.0626929,fusion score:0.0629585\n",
      "\n",
      "Training until validation scores don't improve for 110 rounds.\n",
      "[200]\ttraining's l1: 13.3598\ttraining's l2: 294.741\tvalid_1's l1: 14.7961\tvalid_1's l2: 372.962\n",
      "Early stopping, best iteration is:\n",
      "[211]\ttraining's l1: 13.2903\ttraining's l2: 291.554\tvalid_1's l1: 14.7696\tvalid_1's l2: 372.055\n",
      "Training until validation scores don't improve for 110 rounds.\n",
      "[200]\ttraining's l2: 294.433\ttraining's rmse: 17.1591\tvalid_1's l2: 372.153\tvalid_1's rmse: 19.2913\n",
      "Early stopping, best iteration is:\n",
      "[150]\ttraining's l2: 308.913\ttraining's rmse: 17.5759\tvalid_1's l2: 371.264\tvalid_1's rmse: 19.2682\n",
      "[0]\tvalidation_0-mae:555.832\tvalidation_1-mae:555.878\n",
      "Multiple eval metrics have been passed: 'validation_1-mae' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mae hasn't improved in 100 rounds.\n",
      "[200]\tvalidation_0-mae:14.5706\tvalidation_1-mae:14.9386\n",
      "[400]\tvalidation_0-mae:14.2335\tvalidation_1-mae:14.8773\n",
      "Stopping. Best iteration:\n",
      "[487]\tvalidation_0-mae:14.1112\tvalidation_1-mae:14.8544\n",
      "\n",
      "[0]\tvalidation_0-rmse:600.478\tvalidation_1-rmse:600.546\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[200]\tvalidation_0-rmse:19.1763\tvalidation_1-rmse:19.6993\n",
      "[400]\tvalidation_0-rmse:18.5896\tvalidation_1-rmse:19.3827\n",
      "[600]\tvalidation_0-rmse:18.2835\tvalidation_1-rmse:19.3\n",
      "[800]\tvalidation_0-rmse:18.0318\tvalidation_1-rmse:19.2755\n",
      "[1000]\tvalidation_0-rmse:17.8068\tvalidation_1-rmse:19.2486\n",
      "[1200]\tvalidation_0-rmse:17.5859\tvalidation_1-rmse:19.2264\n",
      "Stopping. Best iteration:\n",
      "[1195]\tvalidation_0-rmse:17.5927\tvalidation_1-rmse:19.225\n",
      "\n",
      "Round:5.0,clf1 score:0.0634290,clf2 score:0.0634876,clf3 score:0.0630720,clf4 score:0.0635214,fusion score:0.0636837\n",
      "\n",
      "Training until validation scores don't improve for 110 rounds.\n",
      "[200]\ttraining's l1: 13.3866\ttraining's l2: 295.488\tvalid_1's l1: 14.5023\tvalid_1's l2: 357.581\n",
      "Early stopping, best iteration is:\n",
      "[120]\ttraining's l1: 13.8937\ttraining's l2: 319.761\tvalid_1's l1: 14.5191\tvalid_1's l2: 357.424\n",
      "Training until validation scores don't improve for 110 rounds.\n",
      "[200]\ttraining's l2: 295.984\ttraining's rmse: 17.2042\tvalid_1's l2: 357.671\tvalid_1's rmse: 18.9122\n",
      "Early stopping, best iteration is:\n",
      "[262]\ttraining's l2: 279.985\ttraining's rmse: 16.7327\tvalid_1's l2: 356.623\tvalid_1's rmse: 18.8845\n",
      "[0]\tvalidation_0-mae:555.741\tvalidation_1-mae:555.96\n",
      "Multiple eval metrics have been passed: 'validation_1-mae' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mae hasn't improved in 100 rounds.\n",
      "[200]\tvalidation_0-mae:14.6308\tvalidation_1-mae:14.6458\n",
      "[400]\tvalidation_0-mae:14.3002\tvalidation_1-mae:14.5466\n",
      "[600]\tvalidation_0-mae:14.031\tvalidation_1-mae:14.5152\n",
      "[800]\tvalidation_0-mae:13.8065\tvalidation_1-mae:14.5041\n",
      "Stopping. Best iteration:\n",
      "[730]\tvalidation_0-mae:13.8786\tvalidation_1-mae:14.4916\n",
      "\n",
      "[0]\tvalidation_0-rmse:600.459\tvalidation_1-rmse:600.636\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[200]\tvalidation_0-rmse:19.1837\tvalidation_1-rmse:19.2722\n",
      "[400]\tvalidation_0-rmse:18.6232\tvalidation_1-rmse:19.0048\n",
      "[600]\tvalidation_0-rmse:18.3325\tvalidation_1-rmse:18.9423\n",
      "[800]\tvalidation_0-rmse:18.0755\tvalidation_1-rmse:18.8926\n",
      "[1000]\tvalidation_0-rmse:17.851\tvalidation_1-rmse:18.877\n",
      "[1200]\tvalidation_0-rmse:17.6433\tvalidation_1-rmse:18.8564\n",
      "[1400]\tvalidation_0-rmse:17.4371\tvalidation_1-rmse:18.8418\n",
      "Stopping. Best iteration:\n",
      "[1459]\tvalidation_0-rmse:17.3825\tvalidation_1-rmse:18.8355\n",
      "\n",
      "Round:6.0,clf1 score:0.0644223,clf2 score:0.0645333,clf3 score:0.0645725,clf4 score:0.0647428,fusion score:0.0649173\n",
      "\n",
      "Training until validation scores don't improve for 110 rounds.\n",
      "[200]\ttraining's l1: 13.3508\ttraining's l2: 294.808\tvalid_1's l1: 14.7018\tvalid_1's l2: 358.86\n",
      "Early stopping, best iteration is:\n",
      "[206]\ttraining's l1: 13.3096\ttraining's l2: 292.857\tvalid_1's l1: 14.698\tvalid_1's l2: 358.676\n",
      "Training until validation scores don't improve for 110 rounds.\n",
      "[200]\ttraining's l2: 295.043\ttraining's rmse: 17.1768\tvalid_1's l2: 363.6\tvalid_1's rmse: 19.0683\n",
      "Early stopping, best iteration is:\n",
      "[163]\ttraining's l2: 305.575\ttraining's rmse: 17.4807\tvalid_1's l2: 362.338\tvalid_1's rmse: 19.0352\n",
      "[0]\tvalidation_0-mae:555.762\tvalidation_1-mae:556.304\n",
      "Multiple eval metrics have been passed: 'validation_1-mae' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mae hasn't improved in 100 rounds.\n",
      "[200]\tvalidation_0-mae:14.5865\tvalidation_1-mae:14.8475\n",
      "[400]\tvalidation_0-mae:14.2558\tvalidation_1-mae:14.7634\n",
      "Stopping. Best iteration:\n",
      "[399]\tvalidation_0-mae:14.2571\tvalidation_1-mae:14.7631\n",
      "\n",
      "[0]\tvalidation_0-rmse:600.444\tvalidation_1-rmse:600.9\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[200]\tvalidation_0-rmse:19.183\tvalidation_1-rmse:19.2821\n",
      "[400]\tvalidation_0-rmse:18.6155\tvalidation_1-rmse:19.0599\n",
      "[600]\tvalidation_0-rmse:18.3248\tvalidation_1-rmse:19.0109\n",
      "[800]\tvalidation_0-rmse:18.0656\tvalidation_1-rmse:18.9848\n",
      "Stopping. Best iteration:\n",
      "[896]\tvalidation_0-rmse:17.9536\tvalidation_1-rmse:18.9813\n",
      "\n",
      "Round:7.0,clf1 score:0.0637223,clf2 score:0.0634785,clf3 score:0.0634305,clf4 score:0.0635786,fusion score:0.0639112\n",
      "\n",
      "Training until validation scores don't improve for 110 rounds.\n",
      "[200]\ttraining's l1: 13.3506\ttraining's l2: 294.343\tvalid_1's l1: 14.5952\tvalid_1's l2: 356.392\n",
      "Early stopping, best iteration is:\n",
      "[170]\ttraining's l1: 13.5438\ttraining's l2: 303.423\tvalid_1's l1: 14.5893\tvalid_1's l2: 355.955\n",
      "Training until validation scores don't improve for 110 rounds.\n",
      "[200]\ttraining's l2: 294.887\ttraining's rmse: 17.1723\tvalid_1's l2: 356.076\tvalid_1's rmse: 18.87\n",
      "Early stopping, best iteration is:\n",
      "[118]\ttraining's l2: 320.123\ttraining's rmse: 17.892\tvalid_1's l2: 354.867\tvalid_1's rmse: 18.8379\n",
      "[0]\tvalidation_0-mae:555.754\tvalidation_1-mae:556.318\n",
      "Multiple eval metrics have been passed: 'validation_1-mae' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mae hasn't improved in 100 rounds.\n",
      "[200]\tvalidation_0-mae:14.6029\tvalidation_1-mae:14.6864\n",
      "[400]\tvalidation_0-mae:14.2674\tvalidation_1-mae:14.5674\n",
      "[600]\tvalidation_0-mae:14.004\tvalidation_1-mae:14.5419\n",
      "[800]\tvalidation_0-mae:13.7743\tvalidation_1-mae:14.5115\n",
      "Stopping. Best iteration:\n",
      "[771]\tvalidation_0-mae:13.805\tvalidation_1-mae:14.5096\n",
      "\n",
      "[0]\tvalidation_0-rmse:600.432\tvalidation_1-rmse:600.943\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[200]\tvalidation_0-rmse:19.2049\tvalidation_1-rmse:19.1831\n",
      "[400]\tvalidation_0-rmse:18.6414\tvalidation_1-rmse:18.894\n",
      "[600]\tvalidation_0-rmse:18.3461\tvalidation_1-rmse:18.8186\n",
      "[800]\tvalidation_0-rmse:18.0835\tvalidation_1-rmse:18.7761\n",
      "[1000]\tvalidation_0-rmse:17.8595\tvalidation_1-rmse:18.7606\n",
      "[1200]\tvalidation_0-rmse:17.6545\tvalidation_1-rmse:18.7449\n",
      "[1400]\tvalidation_0-rmse:17.4567\tvalidation_1-rmse:18.7359\n",
      "Stopping. Best iteration:\n",
      "[1347]\tvalidation_0-rmse:17.5096\tvalidation_1-rmse:18.7334\n",
      "\n",
      "Round:8.0,clf1 score:0.0641516,clf2 score:0.0640999,clf3 score:0.0645094,clf4 score:0.0644074,fusion score:0.0646473\n",
      "\n",
      "Training until validation scores don't improve for 110 rounds.\n",
      "[200]\ttraining's l1: 13.3538\ttraining's l2: 294.521\tvalid_1's l1: 14.6828\tvalid_1's l2: 365.663\n",
      "Early stopping, best iteration is:\n",
      "[134]\ttraining's l1: 13.7568\ttraining's l2: 313.777\tvalid_1's l1: 14.6648\tvalid_1's l2: 364.798\n",
      "Training until validation scores don't improve for 110 rounds.\n",
      "[200]\ttraining's l2: 295.336\ttraining's rmse: 17.1854\tvalid_1's l2: 367.664\tvalid_1's rmse: 19.1746\n",
      "Early stopping, best iteration is:\n",
      "[235]\ttraining's l2: 286.411\ttraining's rmse: 16.9237\tvalid_1's l2: 367.018\tvalid_1's rmse: 19.1577\n",
      "[0]\tvalidation_0-mae:555.773\tvalidation_1-mae:556.404\n",
      "Multiple eval metrics have been passed: 'validation_1-mae' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mae hasn't improved in 100 rounds.\n",
      "[200]\tvalidation_0-mae:14.6031\tvalidation_1-mae:14.7947\n",
      "[400]\tvalidation_0-mae:14.2502\tvalidation_1-mae:14.7025\n",
      "Stopping. Best iteration:\n",
      "[444]\tvalidation_0-mae:14.1853\tvalidation_1-mae:14.6929\n",
      "\n",
      "[0]\tvalidation_0-rmse:600.441\tvalidation_1-rmse:601.045\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[200]\tvalidation_0-rmse:19.1874\tvalidation_1-rmse:19.38\n",
      "[400]\tvalidation_0-rmse:18.6232\tvalidation_1-rmse:19.171\n",
      "[600]\tvalidation_0-rmse:18.322\tvalidation_1-rmse:19.1232\n",
      "[800]\tvalidation_0-rmse:18.0662\tvalidation_1-rmse:19.0949\n",
      "[1000]\tvalidation_0-rmse:17.8332\tvalidation_1-rmse:19.0635\n",
      "[1200]\tvalidation_0-rmse:17.622\tvalidation_1-rmse:19.0564\n",
      "[1400]\tvalidation_0-rmse:17.4168\tvalidation_1-rmse:19.0393\n",
      "Stopping. Best iteration:\n",
      "[1382]\tvalidation_0-rmse:17.434\tvalidation_1-rmse:19.0377\n",
      "\n",
      "Round:9.0,clf1 score:0.0638641,clf2 score:0.0636693,clf3 score:0.0637413,clf4 score:0.0639674,fusion score:0.0641918\n",
      "\n",
      "Training until validation scores don't improve for 110 rounds.\n",
      "[200]\ttraining's l1: 13.3489\ttraining's l2: 294.003\tvalid_1's l1: 14.6806\tvalid_1's l2: 370.372\n",
      "Early stopping, best iteration is:\n",
      "[136]\ttraining's l1: 13.7555\ttraining's l2: 313.131\tvalid_1's l1: 14.6795\tvalid_1's l2: 369.535\n",
      "Training until validation scores don't improve for 110 rounds.\n",
      "[200]\ttraining's l2: 294.785\ttraining's rmse: 17.1693\tvalid_1's l2: 370.268\tvalid_1's rmse: 19.2423\n",
      "Early stopping, best iteration is:\n",
      "[217]\ttraining's l2: 290.006\ttraining's rmse: 17.0296\tvalid_1's l2: 369.788\tvalid_1's rmse: 19.2299\n",
      "[0]\tvalidation_0-mae:555.759\tvalidation_1-mae:556.542\n",
      "Multiple eval metrics have been passed: 'validation_1-mae' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mae hasn't improved in 100 rounds.\n",
      "[200]\tvalidation_0-mae:14.5829\tvalidation_1-mae:14.7788\n",
      "[400]\tvalidation_0-mae:14.2606\tvalidation_1-mae:14.6509\n",
      "[600]\tvalidation_0-mae:13.9979\tvalidation_1-mae:14.6083\n",
      "[800]\tvalidation_0-mae:13.7809\tvalidation_1-mae:14.6008\n",
      "Stopping. Best iteration:\n",
      "[815]\tvalidation_0-mae:13.7623\tvalidation_1-mae:14.5936\n",
      "\n",
      "[0]\tvalidation_0-rmse:600.406\tvalidation_1-rmse:601.147\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[200]\tvalidation_0-rmse:19.1626\tvalidation_1-rmse:19.5179\n",
      "[400]\tvalidation_0-rmse:18.5905\tvalidation_1-rmse:19.2551\n",
      "[600]\tvalidation_0-rmse:18.304\tvalidation_1-rmse:19.2005\n",
      "[800]\tvalidation_0-rmse:18.0574\tvalidation_1-rmse:19.1568\n",
      "[1000]\tvalidation_0-rmse:17.8283\tvalidation_1-rmse:19.1419\n",
      "Stopping. Best iteration:\n",
      "[1052]\tvalidation_0-rmse:17.7757\tvalidation_1-rmse:19.1392\n",
      "\n",
      "Round:10.0,clf1 score:0.0637906,clf2 score:0.0638106,clf3 score:0.0641189,clf4 score:0.0639761,fusion score:0.0642978\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,(train_index,val_index) in enumerate(kf.split(train,label)):\n",
    "        X_train = train.loc[train_index,:]\n",
    "        y_train = label[train_index]\n",
    "        X_val = train.loc[val_index,:]\n",
    "        y_val = label[val_index]\n",
    "        \n",
    "        clf1.fit(X_train,y_train,eval_set=[(X_train,y_train),(X_val,y_val)],\n",
    "                 eval_metric='mae',early_stopping_rounds=110,verbose=200)\n",
    "        pred_val1 = clf1.predict(X_val,num_iteration=clf1.best_iteration_)\n",
    "        val1_mae = mean_absolute_error(y_val,np.round(pred_val1))\n",
    "        pred_test1 = clf1.predict(test,num_iteration = clf1.best_iteration_)\n",
    "        \n",
    "        clf2.fit(X_train,y_train,eval_set=[(X_train,y_train),(X_val,y_val)],\n",
    "                 eval_metric='rmse',early_stopping_rounds=110,verbose=200)\n",
    "        pred_val2 = clf2.predict(X_val,num_iteration = clf2.best_iteration_)\n",
    "        val2_mae = mean_absolute_error(y_val,np.round(pred_val2))\n",
    "        pred_test2 = clf2.predict(test,num_iteration = clf2.best_iteration_)\n",
    "        \n",
    "        clf3.fit(X_train,y_train,eval_set=[(X_train,y_train),(X_val,y_val)],\n",
    "                 eval_metric='mae',early_stopping_rounds=100,verbose=200)\n",
    "        pred_val3 = clf3.predict(X_val,ntree_limit=clf3.best_ntree_limit)\n",
    "        val3_mae = mean_absolute_error(y_val,np.round(pred_val3))\n",
    "        pred_test3 = clf3.predict(test,ntree_limit=clf3.best_ntree_limit)\n",
    "        \n",
    "        clf4.fit(X_train,y_train,eval_set=[(X_train,y_train),(X_val,y_val)],\n",
    "                 eval_metric='rmse',early_stopping_rounds=100,verbose=200)\n",
    "        pred_val4 = clf4.predict(X_val,ntree_limit=clf4.best_ntree_limit)\n",
    "        val4_mae = mean_absolute_error(y_val,np.round(pred_val4))\n",
    "        pred_test4 = clf4.predict(test,ntree_limit=clf4.best_ntree_limit)\n",
    "        \n",
    "        \n",
    "        pred_val = np.round(pred_val1*0.25 + pred_val2*0.25 + pred_val3*0.25 + pred_val4*0.25)\n",
    "        vali_mae = mean_absolute_error(y_val,pred_val)\n",
    "        best_score.append(1/(1+vali_mae))\n",
    "        \n",
    "        pred_test = np.round(pred_test1*0.25 + pred_test2*0.25 + pred_test3*0.25 + pred_test4*0.25)\n",
    "        sub_list.append(pred_test)\n",
    "        \n",
    "        print('Round:{:.1f},clf1 score:{:.7f},clf2 score:{:.7f},clf3 score:{:.7f},clf4 score:{:.7f},fusion score:{:.7f}\\n'.\n",
    "             format(i+1,1/(1+val1_mae),1/(1+val2_mae),1/(1+val3_mae),1/(1+val4_mae),1/(1+vali_mae)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "df431cc47f8758ea06e112c43072b234ef0ad52b"
   },
   "outputs": [],
   "source": [
    "pred_test = np.mean(np.array(sub_list[2:]),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "ff0baf39dca1c44f5bf965df4cdddd2b692c8483"
   },
   "outputs": [],
   "source": [
    "test_data_sub1 = pd.DataFrame()\n",
    "test_data_sub1['id'] = test_id\n",
    "test_data_sub1['score'] =  pred_test\n",
    "test_data_sub1.columns = ['id','score']\n",
    "test_data_sub1['score'] = test_data_sub1['score'].apply(lambda x: int(np.round(x)))\n",
    "test_data_sub1[['id','score']].to_csv('lgb_xgb_stacking_mae_mse.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "dffb4615cbd13ede6f7bc5c434adac06dfefa581"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 54 is out of bounds for axis 0 with size 54",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-bf0a94a8d277>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimportance_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m55\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mimportance_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 54 is out of bounds for axis 0 with size 54"
     ]
    }
   ],
   "source": [
    "importance_features = []\n",
    "for i in range(0,55):\n",
    "    importance_features.append((clf1.feature_importances_[i],X_train.columns[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "efe3a7a23ab33f79f762d50cd3a341e6d0cd72b6"
   },
   "outputs": [],
   "source": [
    "importance_features.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "adebc71308f2c113f28def29d307725e5a298819"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '当月是否逛过福州仓山万达'),\n",
       " (0, '是否_商场_电影_体育馆'),\n",
       " (0, '是否大学生客户'),\n",
       " (1, '当月是否到过福州山姆会员店'),\n",
       " (1, '是否_商场_体育馆'),\n",
       " (1, '是否_商场_旅游'),\n",
       " (1, '是否_商场_旅游_体育馆'),\n",
       " (1, '是否_商场_电影'),\n",
       " (1, '是否黑名单客户'),\n",
       " (1, '用户最近一次缴费距今时长（月）'),\n",
       " (2, '是否_商场_体育馆_电影_旅游'),\n",
       " (2, '是否_商场_电影_旅游'),\n",
       " (2, '用户实名制是否通过核实'),\n",
       " (3, '当月飞机类应用使用次数'),\n",
       " (3, '是否_体育馆_电影_旅游'),\n",
       " (4, '当月物流快递类应用使用次数'),\n",
       " (4, '是否去过高档商场'),\n",
       " (8, '当月是否看电影'),\n",
       " (9, '当月火车类应用使用次数'),\n",
       " (9, '是否_电影_体育馆'),\n",
       " (9, '是否_电影_旅游'),\n",
       " (10, '充值方式2'),\n",
       " (10, '是否_旅游_体育馆'),\n",
       " (11, '是否经常逛商场的人'),\n",
       " (12, '交通类应用使用次数'),\n",
       " (14, '当月是否体育场馆消费'),\n",
       " (21, '充值方式1'),\n",
       " (22, '当月是否景点游览'),\n",
       " (27, '是否4G不健康客户'),\n",
       " (29, '缴费用户当前是否欠费缴费'),\n",
       " (40, '缴费用户最近一次缴费金额（元）'),\n",
       " (53, '当月旅游资讯类应用使用次数'),\n",
       " (78, '用户话费敏感度'),\n",
       " (79, '缴费习惯'),\n",
       " (93, '缴费金额是否能覆盖当月账单'),\n",
       " (97, '用户当月账户余额（元）'),\n",
       " (110, '最近一次交费是否超过平均消费额'),\n",
       " (113, '近三个月月均商场出现次数'),\n",
       " (131, '费用/余额'),\n",
       " (143, '用户账单当月总费用（元）'),\n",
       " (147, '当月金融理财类应用使用总次数'),\n",
       " (151, '账户余额利用率'),\n",
       " (158, '当月网购类应用使用次数'),\n",
       " (179, '通话人均花费'),\n",
       " (184, '当月视频播放类应用使用次数'),\n",
       " (189, '当月账单是否超过平均消费额'),\n",
       " (191, '网龄/年龄'),\n",
       " (198, '近半年账单'),\n",
       " (208, '网龄年龄差'),\n",
       " (211, '最近账单稳定性'),\n",
       " (222, '当月通话交往圈人数'),\n",
       " (224, '用户近6个月平均消费值（元）'),\n",
       " (308, '用户网龄（月）'),\n",
       " (355, '用户年龄')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance_features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
